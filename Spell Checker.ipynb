{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Spell Checker using noisy channel correction\n",
    "\n",
    "#Logic to be constructed!\n",
    "#construct confusion matrix using the file spell_error.txt all sub, ins, del, trans -- This is the model\n",
    "#read test data file.\n",
    "#for the first word generate the candidate generation words using one edit distance.\n",
    "#While generating the candidate pairs, send the possible candidate and also the edit type: sub, ins, del, trans\n",
    "#for all the candidate pairs loop\n",
    "# if the edit type is del, look up for del matrix.\n",
    "# In the del matrix search for del[wi-i,wi]/count[wi-iwi], count is the count from the count mapped against w correct candidate\n",
    "#Calculate individal probabilties and save the result. Here p(w) is calculated against the total count of words\n",
    "# for all the candidates look for max probablites and that will be p(w/x). This has to be the results\n",
    "# Save it against the record.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joby/anaconda/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re \n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File_Corpus = 'test_data/count_1w.txt'\n",
    "\n",
    "File_Corpus = 'test_data/big.txt'\n",
    "File_Spell_Errors='test_data/spell-errors.txt'\n",
    "\n",
    "Test_Data = 'test_data/test.csv'\n",
    "\n",
    "text = open(File_Spell_Errors).read()\n",
    "lines = text.split(\"\\n\")\n",
    "dictionary = {}\n",
    "for line in lines:\n",
    "    key = line.strip().split(\": \")[0]\n",
    "    value = line.strip().split(\": \")[1]\n",
    "    list1 = value.split(\", \")\n",
    "    dictionary[key] = list1\n",
    "\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open(File_Corpus).read()))\n",
    "\n",
    "def read_csv_file(filename):\n",
    "    error_words = []\n",
    " \n",
    "    with open(filename) as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "        next(csvReader)\n",
    "        for row in csvReader:\n",
    "            error_words.append(row[1])\n",
    " \n",
    "    return error_words\n",
    "    \n",
    "    \n",
    "def test_corpus(filename):\n",
    "    text = open(filename).read()\n",
    "    return dict((x.split(' ')[0],int(x.split(' ')[1])) for x in text.split('\\n'))\n",
    "\n",
    "#WORDS = test_corpus(File_Corpus)\n",
    "\n",
    "test_words = read_csv_file(Test_Data)\n",
    "\n",
    "def write_to_file(wordlist):\n",
    "    df = pd.DataFrame(wordlist)\n",
    "    df.to_csv(\"Output/test_submit_main.csv\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pdist(counter):\n",
    "    \"Make a probability distribution, given evidence from a Counter.\"\n",
    "    N = sum(list(counter.values()))\n",
    "    return lambda x: counter[x]/N\n",
    "\n",
    "P = pdist(WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"    \n",
    "    #print(candidates(word))\n",
    "    list_correct_words = []\n",
    "    candidate_words = candidates(word)\n",
    "    for rightWord in candidate_words:\n",
    "        if rightWord in dictionary:\n",
    "            if word in dictionary.get(rightWord):\n",
    "                list_correct_words.append(rightWord)\n",
    "    if list_correct_words:\n",
    "        return max(list_correct_words, key=P)\n",
    "    return max(candidate_words, key = P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS.keys())\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nessisitates\n"
     ]
    }
   ],
   "source": [
    "#P('imidatly')*math.pow(10,10)\n",
    "print(correction('nessisitates'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_list=[]\n",
    "for w in test_words:\n",
    "    correct_list.append(correction(w))\n",
    "\n",
    "#for w in correct_list:\n",
    " #   print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving to file\n",
    "\n",
    "write_to_file(correct_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
